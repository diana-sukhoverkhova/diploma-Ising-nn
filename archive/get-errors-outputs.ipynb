{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efd14ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss, accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e058dea-169c-4432-9b7c-32b19223c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155b014d-9739-4be7-8324-97f72e9fa2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64fbf17-6a9b-4dde-8c39-358a7d72824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(Jd, l, num_conf, T, num_temps, batch_size, shuffle_opt, opt='train'):\n",
    "    datasets = []\n",
    "    spins_loaded = np.load(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npz')\n",
    "    answ_loaded = np.load(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}.npz')\n",
    "    for j in range(num_temps):\n",
    "        \n",
    "        #path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[j]}.npy'\n",
    "        #with open(path, 'rb') as f:\n",
    "        #    x = np.load(f)   \n",
    "        x = spins_loaded[f'T_{j}']\n",
    "        tensor_x = torch.Tensor(x).unsqueeze(1)\n",
    "\n",
    "        #path = f'data_spins/{Jd}_{opt}/answ_{l}_{T[j]}.npy'\n",
    "        #with open(path, 'rb') as f:\n",
    "        #    y = np.load(f)\n",
    "        y = answ_loaded[f'T_{j}']\n",
    "        tensor_y = torch.from_numpy(y).type(torch.float32)\n",
    "\n",
    "        datasets.append(TensorDataset(tensor_x, tensor_y))\n",
    "\n",
    "\n",
    "    dataset = torch.utils.data.ConcatDataset(datasets)\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03fb99-6cef-48ea-88ac-6379802ecda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, l):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.act_hid = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(64*int(l/2-1)*int(l/2-1), 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.act_hid(x)\n",
    "        x = x.view(-1, 64*int(l/2-1)*int(l/2-1))\n",
    "        x = self.fc1(x)\n",
    "        x = self.act_hid(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105afa5-faec-4e13-b9e2-47619375ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(l, train_dataloader, num_epoch, criterion, batch_size):\n",
    "    model = Net(l)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4)\n",
    "    act = nn.Sigmoid()\n",
    "\n",
    "    for epoch in range(num_epoch):  \n",
    "        running_loss = 0.0\n",
    "        accuracy = 0.0\n",
    "        pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        for i, data in pbar:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)  \n",
    "            \n",
    "            model.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #outputs = act(outputs)\n",
    "\n",
    "            outputs = outputs.squeeze(1) # к одной размерности с labels\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            accuracy += (batch_size - sum(abs(labels - act(outputs)))).float().mean()\n",
    "\n",
    "            pbar.set_description(\n",
    "                    f\"Loss: {running_loss/((i+1)*batch_size)} \"\n",
    "                    f\"Accuracy: {accuracy * 100  / ((i+1)*batch_size)}\"\n",
    "            )\n",
    "\n",
    "    print('Training completed')\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf748725-ccb0-44b7-b4c9-d13b8ea4177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, test_dataloader, criterion, batch_size):\n",
    "    outp = []\n",
    "    errors = []\n",
    "    accuracy = 0.0\n",
    "    labels_all = []\n",
    "    act = nn.Sigmoid()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.to(device)\n",
    "            outputs = model(inputs)\n",
    "            #outputs = act(outputs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "            outp.append(act(outputs).item())\n",
    "            loss = criterion(outputs, labels)\n",
    "            errors.append(loss.item())\n",
    "            \n",
    "            accuracy += sum(abs(labels - act(outputs))).float().mean()\n",
    "            \n",
    "            labels_all.append(labels.item())\n",
    "    \n",
    "    accuracy = (1 - accuracy / len(test_dataloader)) * 100\n",
    "    mse = mean_squared_error(labels_all, outp, squared=False)\n",
    "    logloss = log_loss(labels_all, outp)\n",
    "    \n",
    "    print(\"Accuracy = {}\".format(accuracy))\n",
    "    print(\"MSE = {}\".format(mse))\n",
    "    print(\"LogLoss = {}\".format(logloss))\n",
    "    return outp, errors, labels_all, accuracy, mse, logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af144cb-636c-44a9-8d7a-a224e0e32e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = [2.2691853142129728, 2.104982167992544, 1.932307699120554, 1.749339162933206, 1.5536238493280832, 1.34187327905057, 1.109960313758399, 0.8541630993606272, 0.5762735442012712, 0.2885386111960936, 0.03198372863548067]\n",
    "jds = [0.0, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9, -1.0]\n",
    "get_crit_T = dict(zip(jds, roots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb623d-8891-4c39-88bc-2864d88639c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### training ###\n",
    "\n",
    "def train_and_save(Jd, l, num_temps):\n",
    "    num_conf_tr = 2048\n",
    "    num_conf_ts = 512\n",
    "    num_epoch = 1\n",
    "\n",
    "    T_c = get_crit_T[Jd]\n",
    "    T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "    #T = np.round(np.linspace(T_c - 10**-2.0, T_c + 10**-2.0, num_temps), 4)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()     \n",
    "\n",
    "    train_dataloader = load_data(Jd, l, num_conf_tr, T, num_temps, batch_size=4, shuffle_opt=True, opt='train')\n",
    "    print(f'Start training for L = {l}')\n",
    "    model, optimizer = train(l, train_dataloader, num_epoch, criterion, batch_size=4)\n",
    "\n",
    "    #PATH = f'models/{l}_{Jd}_{T[0]}_{T[-1]}_{num_temps}_{epoch}_epochs.pt'\n",
    "    PATH = f'models/{l}_{Jd}_{T[0]}_{T[-1]}_{num_temps}_close_{epoch}_epochs.pt'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    #PATH = f'models/{l}_{Jd}_{T[0]}_{T[-1]}_{num_temps}_{epoch}_epochs_opt.pt'\n",
    "    PATH = f'models/{l}_{Jd}_{T[0]}_{T[-1]}_{num_temps}_close_{epoch}_epochs_opt.pt'\n",
    "    torch.save(optimizer.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba384dc-79db-4497-9257-5c6434443db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [10]\n",
    "Jd = 0.0\n",
    "num_temps = 100\n",
    "for l in L:\n",
    "    train_and_save(Jd, l, num_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888014e-f790-4bf1-beca-34546fb1f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing ###\n",
    "\n",
    "def get_errs_outs(Jd, l, num_temps):\n",
    "    T_c = get_crit_T[Jd]\n",
    "    #T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "    T = np.round(np.linspace(T_c - 10**-2.0, T_c + 10**-2.0, num_temps), 5)\n",
    "    \n",
    "    num_conf_tr = 2048\n",
    "    num_conf_ts = 512\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()     \n",
    "    \n",
    "    print(f'Start testing for L = {l}, Jd = {Jd}')\n",
    "    model = Net(l)\n",
    "    T_c_ = get_crit_T[0.0]\n",
    "    T_ = np.round(np.linspace(T_c_ - 0.3, T_c_ + 0.3, num_temps), 4)\n",
    "    #T_ = np.round(np.linspace(T_c_ - 10**-2.0, T_c_ + 10**-2.0, num_temps), 4)\n",
    "    #PATH = f'models/{l}_0.0_{T_[0]}_{T_[-1]}_{num_temps}.pt'\n",
    "    PATH = f'models/{l}_0.0_{T_[0]}_{T_[-1]}_{num_temps}_{num_epochs}_epochs.pt'\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.eval()\n",
    "    test_dataloader = load_data(Jd, l, num_conf_ts, T, num_temps, batch_size=1, shuffle_opt=False, opt='test')\n",
    "    outp, errors, labels, accuracy, mse, logloss = testing(model, test_dataloader, criterion, batch_size=1)\n",
    "    return errors, outp, labels, accuracy, mse, logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3df27-1b28-4f41-bcc0-929a031083ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "num_epochs = 5\n",
    "L = [60, 80]\n",
    "for l in L:\n",
    "    metrics[l] = []\n",
    "#Jds = [0.0, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9]\n",
    "Jds = [-0.5]\n",
    "num_temps = 100\n",
    "for Jd in Jds: \n",
    "    for l in L:\n",
    "        errs_outs = get_errs_outs(Jd, l, num_temps)\n",
    "        metrics[l].append([Jd, errs_outs[3], errs_outs[4], errs_outs[5]])\n",
    "        #np.save(f'data_errors/{Jd}_{l}_{num_temps}_{num_epochs}_epochs.npy', errs_outs[0])\n",
    "        np.save(f'data_errors/{Jd}_{l}_{num_temps}_{num_epochs}_epochs_close.npy', errs_outs[0])\n",
    "        #np.save(f'data_errors/{Jd}_{l}_{num_temps}.npy', errs_outs[0])\n",
    "        #np.save(f'data_outputs/{Jd}_{l}_{num_temps}_{num_epochs}_epochs.npy', errs_outs[1])\n",
    "        np.save(f'data_outputs/{Jd}_{l}_{num_temps}_{num_epochs}_epochs_close.npy', errs_outs[1])\n",
    "        #np.save(f'data_outputs/{Jd}_{l}_{num_temps}.npy', errs_outs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3ec07-b0d4-49a8-8cea-cc88a2a68bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb170ecc-b5f0-4623-a718-66e4fbed9835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4243d578-a2f6-40f6-86e0-4f41655ef7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 0\n",
      "\n",
      "No NPZ\n",
      "[1.9692, 1.9752, 1.9813, 1.9874, 1.9934, 1.9995, 2.0055, 2.0116, 2.0177, 2.0237, 2.0298, 2.0359, 2.0419, 2.048, 2.054, 2.0601, 2.0662, 2.0722, 2.0783, 2.0843, 2.0904, 2.0965, 2.1025, 2.1086, 2.1146, 2.1207, 2.1268, 2.1328, 2.1389, 2.1449, 2.151, 2.1571, 2.1631, 2.1692, 2.1752, 2.1813, 2.1874, 2.1934, 2.1995, 2.2055, 2.2116, 2.2177, 2.2237, 2.2298, 2.2359, 2.2419, 2.248, 2.254, 2.2601, 2.2662, 2.2722, 2.2783, 2.2843, 2.2904, 2.2965, 2.3025, 2.3086, 2.3146, 2.3207, 2.3268, 2.3328, 2.3389, 2.3449, 2.351, 2.3571, 2.3631, 2.3692, 2.3752, 2.3813, 2.3874, 2.3934, 2.3995, 2.4055, 2.4116, 2.4177, 2.4237, 2.4298, 2.4359, 2.4419, 2.448, 2.454, 2.4601, 2.4662, 2.4722, 2.4783, 2.4843, 2.4904, 2.4965, 2.5025, 2.5086, 2.5146, 2.5207, 2.5268, 2.5328, 2.5389, 2.5449, 2.551, 2.5571, 2.5631, 2.5692] 100\n",
      "\n",
      "NPZ is available\n"
     ]
    }
   ],
   "source": [
    "l = 100\n",
    "Jd = 1.0\n",
    "num_temps = 100\n",
    "roots = [0.3018336135076354, 0.7883671029813581, 0.9723445185469877, 1.2390777517571931, 1.6410179299284857, 1.9728374883141215, 2.2691853142129728, 2.8007227202811613]\n",
    "ms = [0.0004, 0.0625, 0.125, 0.25, 0.5, 0.75, 1.0, 1.5]\n",
    "get_crit_T = dict(zip(ms, roots))\n",
    "T_c = get_crit_T[Jd]\n",
    "T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "#T = np.round(np.linspace(T_c - 10**-2.0, T_c + 10**-2.0, num_temps), 5)\n",
    "#T = np.round(np.linspace(0.03, 3.5, num_temps), 4)\n",
    "\n",
    "if Jd == 1.0:\n",
    "    opt = 'train'\n",
    "    T_miss = []\n",
    "    for j in range(num_temps):\n",
    "            path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[j]}.npy'\n",
    "            if not os.path.isfile(path):\n",
    "                T_miss.append(T[j])\n",
    "    print(T_miss, len(T_miss))\n",
    "    path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npz'\n",
    "    if not os.path.isfile(path):\n",
    "        print('\\nNo NPZ')\n",
    "    else:\n",
    "        print('\\nNPZ is available')\n",
    "\n",
    "opt = 'test'\n",
    "T_miss = []\n",
    "for j in range(num_temps):\n",
    "        path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[j]}.npy'\n",
    "        if not os.path.isfile(path):\n",
    "            T_miss.append(T[j])\n",
    "print(T_miss, len(T_miss))\n",
    "\n",
    "path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npz'\n",
    "if not os.path.isfile(path):\n",
    "    print('\\nNo NPZ')\n",
    "else:\n",
    "    print('\\nNPZ is available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315fb87-d2a4-4bcd-9ee3-30c783799a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb34293-40d6-4ef4-9736-66a6d93d1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "l = 20\n",
    "model = Net(l).to(device)\n",
    "\n",
    "summary(model, (1, l, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spins_loaded = np.load(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npz')\n",
    "#answ_loaded = np.load(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}.npz')\n",
    "answ_loaded = np.load(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}_modified.npz')\n",
    "for j in range(num_temps):\n",
    "    \n",
    "    #path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[j]}.npy'\n",
    "    #with open(path, 'rb') as f:\n",
    "    #    x = np.load(f)   \n",
    "    x = spins_loaded[f'T_{j}']\n",
    "    \n",
    "    #path = f'data_spins/{Jd}_{opt}/answ_{l}_{T[j]}.npy'\n",
    "    #with open(path, 'rb') as f:\n",
    "    #    y = np.load(f)\n",
    "    y = answ_loaded[f'T_{j}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4d4c1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start compressing for L = 20, Jd = -0.9\n",
      "98\n",
      "Start compressing for L = 30, Jd = -0.9\n",
      "98\n",
      "Start compressing for L = 60, Jd = -0.9\n",
      "98\n",
      "Start compressing for L = 80, Jd = -0.9\n",
      "98\n",
      "Start compressing for L = 120, Jd = -0.9\n",
      "98\n",
      "CPU times: user 2min 18s, sys: 9.17 s, total: 2min 27s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#### !!!! только для -0.9 !!!! \n",
    "\n",
    "L = [20,30,60,80,120]\n",
    "#Jds = [0.0, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8]\n",
    "#Jds = [-0.1, -0.2, -0.3, -0.4, -0.5]\n",
    "Jds = [-0.9]\n",
    "opt = 'test'\n",
    "num_temps = 100\n",
    "\n",
    "for l in L:\n",
    "    for Jd in Jds:\n",
    "        print(f'Start compressing for L = {l}, Jd = {Jd}')\n",
    "\n",
    "        T_c = get_crit_T[Jd]\n",
    "        T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "        #T = np.round(np.linspace(0.03, 3.5, num_temps), 4)\n",
    "        #T = np.round(np.linspace(T_c - 10**-2.0, T_c + 10**-2.0, num_temps), 5)\n",
    "\n",
    "        xs = []\n",
    "        spins_loaded = np.load(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npz')\n",
    "        for j in range(2, num_temps): #### !!!! убираем T<0\n",
    "            x_j = spins_loaded[f'T_{j}']\n",
    "            xs.append(x_j)\n",
    "        \n",
    "        print(len(xs))\n",
    "            \n",
    "        savez_dict = dict()\n",
    "        for j, x_j in enumerate(xs):\n",
    "            savez_dict[f'T_{j}'] = x_j\n",
    "\n",
    "        np.savez_compressed(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}_upd', **savez_dict)\n",
    "\n",
    "        ys = []\n",
    "        answ_loaded = np.load(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}_modified.npz')\n",
    "        for j in range(2, num_temps):\n",
    "            y_j = answ_loaded[f'T_{j}']\n",
    "            ys.append(y_j)\n",
    "            \n",
    "        savez_dict = dict()\n",
    "        for j, y_j in enumerate(ys):\n",
    "            savez_dict[f'T_{j}'] = y_j\n",
    "\n",
    "        np.savez_compressed(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}_modified_upd', **savez_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441f67f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start compressing for L = 120, Jd = 0.0625\n",
      "Start compressing for L = 120, Jd = 0.125\n",
      "CPU times: user 2min 14s, sys: 14 s, total: 2min 28s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#L = [20, 30, 60, 80]\n",
    "L = [120]\n",
    "#Jds = [0.0, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8]\n",
    "#Jds = [-0.1, -0.2, -0.3, -0.4, -0.5]\n",
    "#Jds = [1.0]\n",
    "Jds = [0.0625, 0.125]#, 0.25, 0.5, 0.75, 1.0, 1.5]\n",
    "opt = 'test'\n",
    "num_temps = 100\n",
    "\n",
    "for l in L:\n",
    "    for Jd in Jds:\n",
    "\n",
    "        #Jd = np.round(Jd, 2)\n",
    "        print(f'Start compressing for L = {l}, Jd = {Jd}')\n",
    "\n",
    "        roots = [0.3018336135076354, 0.7883671029813581, 0.9723445185469877, 1.2390777517571931, 1.6410179299284857, 1.9728374883141215, 2.2691853142129728, 2.8007227202811613]\n",
    "        ms = [0.0004, 0.0625, 0.125, 0.25, 0.5, 0.75, 1.0, 1.5]\n",
    "        get_crit_T = dict(zip(ms, roots))\n",
    "        T_c = get_crit_T[Jd]\n",
    "        T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "        #T = np.round(np.linspace(0.03, 3.5, num_temps), 4)\n",
    "        #T = np.round(np.linspace(T_c - 10**-2.0, T_c + 10**-2.0, num_temps), 5)\n",
    "\n",
    "        xs = []\n",
    "        for j in range(num_temps):\n",
    "            path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[j]}.npy'\n",
    "            with open(path, 'rb') as f:\n",
    "                x_j = np.load(f)\n",
    "                xs.append(x_j)\n",
    "            os.remove(path)\n",
    "\n",
    "        savez_dict = dict()\n",
    "        for j, x_j in enumerate(xs):\n",
    "            savez_dict[f'T_{j}'] = x_j\n",
    "\n",
    "        np.savez_compressed(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}', **savez_dict)\n",
    "\n",
    "        ys = []\n",
    "        for j in range(num_temps):\n",
    "            path = f'data_spins/{Jd}_{opt}/answ_{l}_{T[j]}.npy'\n",
    "            with open(path, 'rb') as f:\n",
    "                y_j = np.load(f)\n",
    "                ys.append(y_j)\n",
    "            os.remove(path)\n",
    "\n",
    "        savez_dict = dict()\n",
    "        for j, y_j in enumerate(ys):\n",
    "            savez_dict[f'T_{j}'] = y_j\n",
    "\n",
    "        np.savez_compressed(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}', **savez_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb1930-5dbe-489c-8bb9-3b1b20612275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02fa2fc-84be-40dc-8644-2a55c615528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 80\n",
    "Jd = 0.0\n",
    "T_c = get_crit_T[Jd]\n",
    "T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "\n",
    "loaded = np.load(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npz')\n",
    "loaded['T_0'] == loaded['T_69']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d175457-35ad-45f4-9cd7-c13ce4de6efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 0.0\n",
    "\n",
    "#L = [10, 20, 30, 60, 80]\n",
    "L = [80]\n",
    "Jd = 0.0\n",
    "opt = 'test'\n",
    "num_temps = 100\n",
    "\n",
    "T_c = get_crit_T[Jd]\n",
    "T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "#spins_loaded = np.load(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npz')\n",
    "#answ_loaded = np.load(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}.npz')\n",
    "for j in range(num_temps):\n",
    "    for l in L:\n",
    "        path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[j]}.npy'\n",
    "        with open(path, 'rb') as f:\n",
    "            x = np.load(f)   \n",
    "        total_size += x.nbytes\n",
    "        #x = spins_loaded[f'T_{j}']\n",
    "        #tensor_x = torch.Tensor(x).unsqueeze(1)\n",
    "print(total_size / (1024 * 1024 * 1024))\n",
    "#round(getsizeof(a) / 1024 / 1024,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27c18b-e013-40ec-bcaf-576bbd98dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 80\n",
    "Jd = 0.0\n",
    "T_c = get_crit_T[Jd]\n",
    "T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "\n",
    "loaded = np.load(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npz')\n",
    "loaded['T_0'].nbytes / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6dfa6-7c56-43b0-9c89-e3ae48addc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from zipfile import ZipFile, ZIP_LZMA, ZIP_BZIP2\n",
    "\n",
    "L = [80]\n",
    "Jds = [0.0]\n",
    "opt = 'train'\n",
    "num_temps = 100\n",
    "\n",
    "for l in L:\n",
    "    for Jd in Jds:\n",
    "        \n",
    "        print(f'Start compressing for L = {l}, Jd = {Jd}')\n",
    "        \n",
    "        T_c = get_crit_T[Jd]\n",
    "        T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "        #T = np.round(np.linspace(0.03, 3.5, num_temps), 4)\n",
    "\n",
    "        xs = []\n",
    "        for j in range(num_temps):\n",
    "            path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[j]}.npy'\n",
    "            with open(path, 'rb') as f:\n",
    "                x_j = np.load(f)\n",
    "                xs.append(x_j)\n",
    "\n",
    "        #savez_dict = dict()\n",
    "        #for j, x_j in enumerate(xs):\n",
    "        #    savez_dict[f'T_{j}'] = x_j\n",
    "\n",
    "        #np.savez_compressed(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}', **savez_dict)\n",
    "        \n",
    "        np.save(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npy', xs)\n",
    "\n",
    "        with ZipFile(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}_bzip.zip', 'w', compression=ZIP_BZIP2) as myzip:\n",
    "            myzip.write(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npy')\n",
    "        \n",
    "        myzip.close()\n",
    "        \n",
    "        ys = []\n",
    "        for j in range(num_temps):\n",
    "            path = f'data_spins/{Jd}_{opt}/answ_{l}_{T[j]}.npy'\n",
    "            with open(path, 'rb') as f:\n",
    "                y_j = np.load(f)\n",
    "                ys.append(y_j)\n",
    "\n",
    "        #savez_dict = dict()\n",
    "        #for j, y_j in enumerate(ys):\n",
    "        #    savez_dict[f'T_{j}'] = y_j\n",
    "\n",
    "        #np.savez_compressed(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}', **savez_dict)\n",
    "        \n",
    "        np.save(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}.npy', ys)\n",
    "        \n",
    "        with ZipFile(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}_bzip.zip', 'w', compression=ZIP_BZIP2) as myzip:\n",
    "            myzip.write(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}.npy')\n",
    "        myzip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfceb9f3-77f3-4130-9634-80bf8e8dec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from zipfile import ZipFile, ZIP_LZMA, ZIP_BZIP2\n",
    "\n",
    "L = [80]\n",
    "Jds = [0.0]\n",
    "opt = 'train'\n",
    "num_temps = 100\n",
    "\n",
    "for l in L:\n",
    "    for Jd in Jds:\n",
    "        \n",
    "        print(f'Start compressing for L = {l}, Jd = {Jd}')\n",
    "        \n",
    "        T_c = get_crit_T[Jd]\n",
    "        T = np.round(np.linspace(T_c - 0.3, T_c + 0.3, num_temps), 4)\n",
    "        #T = np.round(np.linspace(0.03, 3.5, num_temps), 4)\n",
    "\n",
    "        xs = []\n",
    "        for j in range(num_temps):\n",
    "            path = f'data_spins/{Jd}_{opt}/spins_{l}_{T[j]}.npy'\n",
    "            with open(path, 'rb') as f:\n",
    "                x_j = np.load(f)\n",
    "                xs.append(x_j)\n",
    "\n",
    "        #savez_dict = dict()\n",
    "        #for j, x_j in enumerate(xs):\n",
    "        #    savez_dict[f'T_{j}'] = x_j\n",
    "\n",
    "        #np.savez_compressed(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}', **savez_dict)\n",
    "        \n",
    "        np.save(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npy', xs)\n",
    "\n",
    "        with ZipFile(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}_lzma.zip', 'w', compression=ZIP_LZMA) as myzip:\n",
    "            myzip.write(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}.npy')\n",
    "        \n",
    "        myzip.close()\n",
    "        \n",
    "        ys = []\n",
    "        for j in range(num_temps):\n",
    "            path = f'data_spins/{Jd}_{opt}/answ_{l}_{T[j]}.npy'\n",
    "            with open(path, 'rb') as f:\n",
    "                y_j = np.load(f)\n",
    "                ys.append(y_j)\n",
    "\n",
    "        #savez_dict = dict()\n",
    "        #for j, y_j in enumerate(ys):\n",
    "        #    savez_dict[f'T_{j}'] = y_j\n",
    "\n",
    "        #np.savez_compressed(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}', **savez_dict)\n",
    "        \n",
    "        np.save(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}.npy', ys)\n",
    "        \n",
    "        with ZipFile(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}_lzma.zip', 'w', compression=ZIP_LZMA) as myzip:\n",
    "            myzip.write(f'data_spins/{Jd}_{opt}/answ_{l}_{T[0]}_{T[-1]}.npy')\n",
    "        myzip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d3e9cc6-35a4-4a50-885d-fd92c23e5d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_0 is OK\n",
      "T_1 is OK\n",
      "T_2 is OK\n",
      "T_3 is OK\n",
      "T_4 is OK\n",
      "T_5 is OK\n",
      "T_6 is OK\n",
      "T_7 is OK\n",
      "T_8 is OK\n",
      "T_9 is OK\n",
      "T_10 is OK\n",
      "T_11 is OK\n",
      "T_12 is OK\n",
      "T_13 is OK\n",
      "T_14 is OK\n",
      "T_15 is OK\n",
      "T_16 is OK\n",
      "T_17 is OK\n",
      "T_18 is OK\n",
      "T_19 is OK\n",
      "T_20 is OK\n",
      "T_21 is OK\n",
      "T_22 is OK\n",
      "T_23 is OK\n",
      "T_24 is OK\n",
      "T_25 is OK\n",
      "T_26 is OK\n",
      "T_27 is OK\n",
      "T_28 is OK\n",
      "T_29 is OK\n",
      "T_30 is OK\n",
      "T_31 is OK\n",
      "T_32 is OK\n",
      "T_33 is OK\n",
      "T_34 is OK\n",
      "T_35 is OK\n",
      "T_36 is OK\n",
      "T_37 is OK\n",
      "T_38 is OK\n",
      "T_39 is OK\n",
      "T_40 is OK\n",
      "T_41 is OK\n",
      "T_42 is OK\n",
      "T_43 is OK\n",
      "T_44 is OK\n",
      "T_45 is OK\n",
      "T_46 is OK\n",
      "T_47 is OK\n",
      "T_48 is OK\n",
      "T_49 is OK\n",
      "T_50 is OK\n",
      "T_51 is OK\n",
      "T_52 is OK\n",
      "T_53 is OK\n",
      "T_54 is OK\n",
      "T_55 is OK\n",
      "T_56 is OK\n",
      "T_57 is OK\n",
      "T_58 is OK\n",
      "T_59 is OK\n",
      "T_60 is OK\n",
      "T_61 is OK\n",
      "T_62 is OK\n",
      "T_63 is OK\n",
      "T_64 is OK\n",
      "T_65 is OK\n",
      "T_66 is OK\n",
      "T_67 is OK\n",
      "T_68 is OK\n",
      "T_69 is OK\n",
      "T_70 is OK\n",
      "T_71 is OK\n",
      "T_72 is OK\n",
      "T_73 is OK\n",
      "T_74 is OK\n",
      "T_75 is OK\n",
      "T_76 is OK\n",
      "T_77 is OK\n",
      "T_78 is OK\n",
      "T_79 is OK\n",
      "T_80 is OK\n",
      "T_81 is OK\n",
      "T_82 is OK\n",
      "T_83 is OK\n",
      "T_84 is OK\n",
      "T_85 is OK\n",
      "T_86 is OK\n",
      "T_87 is OK\n",
      "T_88 is OK\n",
      "T_89 is OK\n",
      "T_90 is OK\n",
      "T_91 is OK\n",
      "T_92 is OK\n",
      "T_93 is OK\n",
      "T_94 is OK\n",
      "T_95 is OK\n",
      "T_96 is OK\n",
      "T_97 is OK\n"
     ]
    }
   ],
   "source": [
    "spins_loaded = np.load(f'data_spins/{Jd}_{opt}/spins_{l}_{T[0]}_{T[-1]}_upd.npz')\n",
    "for j in range(num_temps-2): #### !!!! убираем T<0\n",
    "    if spins_loaded[f'T_{j}'] is not None:\n",
    "       print(f'T_{j} is OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd835c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-mc_lib_env]",
   "language": "python",
   "name": "conda-env-.conda-mc_lib_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a359964023e5d8e983355006fff7ce8740f6aad638422887b139eb11370c339"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
